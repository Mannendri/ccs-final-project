{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Procrastination POMDP Model\n",
        "\n",
        "This notebook implements a generative POMDP model for procrastination using memo-lang.\n",
        "\n",
        "**Model Overview:**\n",
        "- Sequential decision-making over H=21 timesteps (3 steps/day × 7 days)\n",
        "- Each participant p has:\n",
        "  - Latent cost per task: θ[p, j] ~ Normal(μ[p, j], σ_θ)\n",
        "  - Baseline work propensity: α[p] ~ Normal(0, σ_α)\n",
        "  - Global urgency sensitivity: β_u (shared across participants)\n",
        "- Prior mean μ[p, j] uses pre-study ratings (difficulty, concreteness, duration, rewardless)\n",
        "- Dynamics per timestep:\n",
        "  1. Choose action (attempt a task) among incomplete tasks using softmax policy\n",
        "  2. Completion probability conditional on attempting task j: sigmoid(α[p] + β_u * urgency - θ[p, j])\n",
        "- Observations: Task completion days (converted to timesteps)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation and Setup\n",
        "\n",
        "**Requirements:**\n",
        "- Python >= 3.12\n",
        "- memo-lang: `pip install memo-lang`\n",
        "- JAX: `pip install jax` (CPU version)\n",
        "- Other dependencies: numpy, pandas, matplotlib, scipy, jupyter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /Users/mannendriolivares/Desktop/ccs-final-project\n",
            "Plots will be saved to: /Users/mannendriolivares/Desktop/ccs-final-project/plots\n",
            "JAX version: 0.8.1\n",
            "✓ memo-lang is installed\n"
          ]
        }
      ],
      "source": [
        "# Imports and setup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from enum import IntEnum\n",
        "from typing import no_type_check\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.scipy.stats.norm import pdf as norm_pdf\n",
        "from jax.scipy.special import expit as sigmoid\n",
        "from scipy.optimize import minimize\n",
        "from memo import memo\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "\n",
        "# Set up paths\n",
        "current_dir = Path.cwd()\n",
        "if (current_dir / 'data').exists():\n",
        "    PROJECT_ROOT = current_dir\n",
        "elif (current_dir.parent / 'data').exists():\n",
        "    PROJECT_ROOT = current_dir.parent\n",
        "elif (current_dir.parent.parent / 'data').exists():\n",
        "    PROJECT_ROOT = current_dir.parent.parent\n",
        "else:\n",
        "    PROJECT_ROOT = current_dir\n",
        "\n",
        "PLOTS_DIR = PROJECT_ROOT / 'plots'\n",
        "PLOTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"Plots will be saved to: {PLOTS_DIR}\")\n",
        "print(f\"JAX version: {jax.__version__}\")\n",
        "\n",
        "# Verify memo is installed\n",
        "try:\n",
        "    from memo import memo\n",
        "    print(\"✓ memo-lang is installed\")\n",
        "except ImportError:\n",
        "    print(\"✗ memo-lang is not installed. Run: pip install memo-lang\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Participants: 6\n",
            "Tasks: 8\n",
            "\n",
            "Participants: ['aphid-1', 'aphid-2', 'gila monster', 'hummingbird', 'kingfisher', 'wagtail']\n",
            "\n",
            "Tasks: ['Analyze a short passage', 'Complete a short quiz', 'Complete fraternity chore', 'Draw for ten minutes', 'Explain a difficult concept from class', 'Solve a logic puzzle', 'Sort a deck of cards', 'Write a brief reflection']\n",
            "\n",
            "String-to-integer mapping example (first task):\n",
            "  Task: Analyze a short passage\n",
            "  Concreteness: low -> 2\n",
            "  Difficulty: hard -> 8\n",
            "  Duration: long -> 8\n",
            "\n",
            "Task properties:\n",
            "  Analyze a short passage: deadline=3, points=20.0\n",
            "  Complete a short quiz: deadline=3, points=5.0\n",
            "  Complete fraternity chore: deadline=5, points=25.0\n",
            "  Draw for ten minutes: deadline=3, points=10.0\n",
            "  Explain a difficult concept from class: deadline=1, points=20.0\n",
            "  Solve a logic puzzle: deadline=5, points=15.0\n",
            "  Sort a deck of cards: deadline=1, points=5.0\n",
            "  Write a brief reflection: deadline=1, points=15.0\n",
            "\n",
            "Completion times (timesteps):\n",
            "  aphid-1: {'Sort a deck of cards': 3, 'Complete a short quiz': 0, 'Complete fraternity chore': None, 'Write a brief reflection': 0, 'Draw for ten minutes': None, 'Solve a logic puzzle': 0, 'Explain a difficult concept from class': 3, 'Analyze a short passage': None}\n",
            "  aphid-2: {'Sort a deck of cards': 6, 'Complete a short quiz': 15, 'Complete fraternity chore': None, 'Write a brief reflection': 15, 'Draw for ten minutes': None, 'Solve a logic puzzle': 15, 'Explain a difficult concept from class': None, 'Analyze a short passage': None}\n",
            "  gila monster: {'Sort a deck of cards': None, 'Complete a short quiz': None, 'Complete fraternity chore': None, 'Write a brief reflection': None, 'Draw for ten minutes': None, 'Solve a logic puzzle': None, 'Explain a difficult concept from class': 3, 'Analyze a short passage': None}\n"
          ]
        }
      ],
      "source": [
        "# Load aggregated data\n",
        "df = pd.read_csv(PROJECT_ROOT / 'data' / 'aggregated_data.csv')\n",
        "\n",
        "# Generic mapping function for string values to integers (1-10)\n",
        "def map_string_to_int(value, string_mapping, field_name):\n",
        "    \"\"\"\n",
        "    Map string values to integers from 1-10.\n",
        "    \n",
        "    Args:\n",
        "        value: String value or numeric value\n",
        "        string_mapping: Dictionary mapping string keys to integer values (e.g., {'low': 2, 'medium': 5, 'high': 8})\n",
        "        field_name: Name of the field being mapped (for warning messages, e.g., 'concreteness', 'difficulty', 'duration')\n",
        "    \n",
        "    Returns:\n",
        "        Integer from 1-10\n",
        "    \"\"\"\n",
        "    if pd.isna(value):\n",
        "        return 5.0  # Default to middle value\n",
        "    \n",
        "    # If already numeric, return it (clamped to 1-10)\n",
        "    if isinstance(value, (int, float)):\n",
        "        return max(1, min(10, float(value)))\n",
        "    \n",
        "    # Map string values\n",
        "    value_str = str(value).lower().strip()\n",
        "    \n",
        "    if value_str in string_mapping:\n",
        "        return string_mapping[value_str]\n",
        "    \n",
        "    # If unrecognized, default to middle value\n",
        "    print(f\"Warning: Unrecognized {field_name} value '{value}', defaulting to 5\")\n",
        "    return 5.0\n",
        "\n",
        "# Specific mapping functions using the generic helper\n",
        "def map_concreteness_to_int(value):\n",
        "    \"\"\"Map string concreteness values ('low', 'medium', 'high') to integers from 1-10.\"\"\"\n",
        "    return map_string_to_int(value, {'low': 2, 'medium': 5, 'high': 8}, 'concreteness')\n",
        "\n",
        "def map_difficulty_to_int(value):\n",
        "    \"\"\"Map string difficulty values ('easy', 'medium', 'hard') to integers from 1-10.\"\"\"\n",
        "    return map_string_to_int(value, {'easy': 2, 'medium': 5, 'hard': 8}, 'difficulty')\n",
        "\n",
        "def map_duration_to_int(value):\n",
        "    \"\"\"Map string duration values ('short', 'medium', 'long') to integers from 1-10.\"\"\"\n",
        "    return map_string_to_int(value, {'short': 2, 'medium': 5, 'long': 8}, 'duration')\n",
        "\n",
        "# Extract unique participants and tasks\n",
        "participants = sorted(df['participant_id'].unique())\n",
        "tasks = sorted(df['task'].unique())\n",
        "n_participants = len(participants)\n",
        "n_tasks = len(tasks)\n",
        "\n",
        "print(f\"Participants: {n_participants}\")\n",
        "print(f\"Tasks: {n_tasks}\")\n",
        "print(f\"\\nParticipants: {participants}\")\n",
        "print(f\"\\nTasks: {tasks}\")\n",
        "\n",
        "# Create mappings\n",
        "participant_to_idx = {p: i for i, p in enumerate(participants)}\n",
        "task_to_idx = {t: i for i, t in enumerate(tasks)}\n",
        "idx_to_task = {i: t for t, i in task_to_idx.items()}\n",
        "\n",
        "# Extract task properties\n",
        "task_data = {}\n",
        "for task in tasks:\n",
        "    task_row = df[df['task'] == task].iloc[0]\n",
        "    \n",
        "    # Map string values to integers\n",
        "    concreteness_val = task_row['task_concreteness']\n",
        "    concreteness_int = map_concreteness_to_int(concreteness_val)\n",
        "    \n",
        "    difficulty_val = task_row['task_difficulty']\n",
        "    difficulty_int = map_difficulty_to_int(difficulty_val)\n",
        "    \n",
        "    duration_val = task_row['task_duration']\n",
        "    duration_int = map_duration_to_int(duration_val)\n",
        "    \n",
        "    task_data[task] = {\n",
        "        'deadline_day': int(task_row['task_deadline_day']),\n",
        "        'points': float(task_row['task_points']),\n",
        "        'concreteness': float(concreteness_int),  # Now always numeric\n",
        "        'difficulty': float(difficulty_int),  # Now always numeric\n",
        "        'duration': float(duration_int)  # Now always numeric\n",
        "    }\n",
        "    \n",
        "    # Print mapping for first task to show it's working\n",
        "    if task == tasks[0]:\n",
        "        print(f\"\\nString-to-integer mapping example (first task):\")\n",
        "        print(f\"  Task: {task}\")\n",
        "        print(f\"  Concreteness: {concreteness_val} -> {concreteness_int}\")\n",
        "        print(f\"  Difficulty: {difficulty_val} -> {difficulty_int}\")\n",
        "        print(f\"  Duration: {duration_val} -> {duration_int}\")\n",
        "\n",
        "# Extract participant-task ratings\n",
        "ratings = {}\n",
        "for _, row in df.iterrows():\n",
        "    p = row['participant_id']\n",
        "    t = row['task']\n",
        "    if p not in ratings:\n",
        "        ratings[p] = {}\n",
        "    ratings[p][t] = {\n",
        "        'perceived_difficulty': float(row['perceived_difficulty']) if pd.notna(row['perceived_difficulty']) else None,\n",
        "        'perceived_concreteness': float(row['perceived_concreteness']) if pd.notna(row['perceived_concreteness']) else None,\n",
        "        'perceived_duration': float(row['perceived_duration']) if pd.notna(row['perceived_duration']) else None,\n",
        "        'perceived_reward': float(row['perceived_reward']) if pd.notna(row['perceived_reward']) else None,\n",
        "    }\n",
        "\n",
        "# Extract completion times\n",
        "completion_times = {}\n",
        "for _, row in df.iterrows():\n",
        "    p = row['participant_id']\n",
        "    t = row['task']\n",
        "    if p not in completion_times:\n",
        "        completion_times[p] = {}\n",
        "    if row['completed'] and pd.notna(row['relative_completion_day']):\n",
        "        # Convert completion day to timestep (3 steps per day, 0-indexed)\n",
        "        # Day 0 = timesteps 0-2, Day 1 = timesteps 3-5, etc.\n",
        "        completion_day = int(row['relative_completion_day'])\n",
        "        # Use the first timestep of that day (coarse mapping)\n",
        "        completion_times[p][t] = completion_day * 3\n",
        "    else:\n",
        "        completion_times[p][t] = None  # Not completed\n",
        "\n",
        "print(f\"\\nTask properties:\")\n",
        "for task in tasks:\n",
        "    print(f\"  {task}: deadline={task_data[task]['deadline_day']}, points={task_data[task]['points']}\")\n",
        "\n",
        "print(f\"\\nCompletion times (timesteps):\")\n",
        "for p in participants[:3]:  # Show first 3\n",
        "    print(f\"  {p}: {completion_times[p]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Hyperparameters\n",
        "\n",
        "Set hyperparameters for priors and model dynamics:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model configuration:\n",
            "  H = 21 timesteps (7 days)\n",
            "  γ = 0.9\n",
            "  η = 1.0\n",
            "  σ_θ = 2.0, σ_α = 1.0, σ_β = 1.0\n"
          ]
        }
      ],
      "source": [
        "# Model hyperparameters\n",
        "H = 21  # Total timesteps (3 per day × 7 days)\n",
        "STEPS_PER_DAY = 3\n",
        "GAMMA = 0.9  # Lateness discount factor\n",
        "ETA = 1.0  # Softmax temperature for action selection\n",
        "\n",
        "# Prior hyperparameters\n",
        "SIGMA_THETA = 2.0  # Prior std for θ[p, j]\n",
        "SIGMA_ALPHA = 1.0  # Prior std for α[p]\n",
        "SIGMA_BETA = 1.0  # Prior std for β_u\n",
        "\n",
        "# Prior mean weights (for μ[p, j] = w_d * diff + w_c * (10-conc) + w_tau * dur + w_r * rewardless)\n",
        "W_DIFFICULTY = 0.5\n",
        "W_CONCRETENESS = 0.3  # Note: using (10 - concreteness) so higher concreteness = lower cost\n",
        "W_DURATION = 0.4\n",
        "W_REWARDLESS = 0.2  # Note: using perceived_reward, so higher reward = lower cost (inverse)\n",
        "\n",
        "print(f\"Model configuration:\")\n",
        "print(f\"  H = {H} timesteps ({H // STEPS_PER_DAY} days)\")\n",
        "print(f\"  γ = {GAMMA}\")\n",
        "print(f\"  η = {ETA}\")\n",
        "print(f\"  σ_θ = {SIGMA_THETA}, σ_α = {SIGMA_ALPHA}, σ_β = {SIGMA_BETA}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Prior Means μ[p, j]\n",
        "\n",
        "Compute prior means for θ[p, j] using pre-study ratings:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prior means μ[p, j] (first few):\n",
            "[[7.3 3.1 3.8 5.7 6.8 4.9 3.3 3.7]\n",
            " [8.5 3.  7.3 4.2 7.9 5.3 2.7 6.9]\n",
            " [6.6 5.2 8.1 4.5 5.3 4.3 2.6 7.5]]\n"
          ]
        }
      ],
      "source": [
        "# Compute prior means μ[p, j] for each participant-task pair\n",
        "mu_prior = np.zeros((n_participants, n_tasks))\n",
        "\n",
        "for p_idx, p in enumerate(participants):\n",
        "    for t_idx, t in enumerate(tasks):\n",
        "        rating = ratings[p][t]\n",
        "        \n",
        "        # Extract ratings (use defaults if missing)\n",
        "        diff = rating['perceived_difficulty'] if rating['perceived_difficulty'] is not None else 5.0\n",
        "        conc = rating['perceived_concreteness'] if rating['perceived_concreteness'] is not None else 5.0\n",
        "        dur = rating['perceived_duration'] if rating['perceived_duration'] is not None else 5.0\n",
        "        reward = rating['perceived_reward'] if rating['perceived_reward'] is not None else 5.0\n",
        "        \n",
        "        # Compute prior mean: higher difficulty, lower concreteness, longer duration, lower reward → higher cost\n",
        "        mu = (W_DIFFICULTY * diff + \n",
        "              W_CONCRETENESS * (10 - conc) +  # Higher concreteness → lower cost\n",
        "              W_DURATION * dur + \n",
        "              W_REWARDLESS * (10 - reward))  # Higher reward → lower cost\n",
        "        \n",
        "        mu_prior[p_idx, t_idx] = mu\n",
        "\n",
        "print(\"Prior means μ[p, j] (first few):\")\n",
        "print(mu_prior[:3, :])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Setup\n",
        "\n",
        "Helper functions and enums for the generative model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task array: [0 1 2 3 4 5 6 7]\n",
            "Task enum: [0, 1, 2, 3, 4, 5, 6, 7]\n"
          ]
        }
      ],
      "source": [
        "# Define enums for memo\n",
        "class TaskIdx(IntEnum):\n",
        "    \"\"\"Task indices (0 to n_tasks-1)\"\"\"\n",
        "    pass\n",
        "\n",
        "# Dynamically create enum values\n",
        "for i, task in enumerate(tasks):\n",
        "    setattr(TaskIdx, f'TASK_{i}', i)\n",
        "\n",
        "# Create task array for memo\n",
        "TASK_ARRAY = np.array(list(range(n_tasks)))\n",
        "\n",
        "# Helper function to get day from timestep\n",
        "# JAX supports // operator natively\n",
        "def day_from_timestep(t):\n",
        "    \"\"\"Convert timestep t to day (0-indexed)\"\"\"\n",
        "    return t // STEPS_PER_DAY\n",
        "\n",
        "# Helper function to compute lateness\n",
        "# Use jnp.maximum here (it's OK in helper functions, just not in memo expressions)\n",
        "# JAX can trace through jnp.maximum in helper functions\n",
        "@jax.jit\n",
        "def lateness(t, deadline_day):\n",
        "    \"\"\"Compute lateness at timestep t for task with deadline_day\"\"\"\n",
        "    current_day = day_from_timestep(t)\n",
        "    return jnp.maximum(0, current_day - deadline_day)\n",
        "\n",
        "print(f\"Task array: {TASK_ARRAY}\")\n",
        "print(f\"Task enum: {[getattr(TaskIdx, f'TASK_{i}') for i in range(n_tasks)]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## POMDP Generative Model\n",
        "\n",
        "We model the completion time for each task as a function of the sequential decision process.\n",
        "Since memo doesnt support loops, we model the probability of completing at each timestep\n",
        "by computing the utility-based probability that accounts for:\n",
        "1. The probability of attempting the task (softmax over incomplete tasks)\n",
        "2. The probability of completing given an attempt (sigmoid)\n",
        "3. The probability that it wasnt completed earlier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## POMDP Generative Model Implementation\n",
        "\n",
        "We implement a generative model that captures the POMDP dynamics:\n",
        "- Action selection via softmax over incomplete tasks\n",
        "- Completion probability via sigmoid given an attempt\n",
        "- Observations of completion times\n",
        "\n",
        "The model computes the probability distribution over completion times for each task,\n",
        "which we then use for MAP inference over the latent parameters θ[p,j], α[p], and β_u.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing task_completion_time model...\n",
            "Model test error: zero-size array to reduction operation max which has no identity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/var/folders/dv/jpj689g17y74xmqj_yjqtyx00000gn/T/ipykernel_4041/1623622540.py\", line 77, in <module>\n",
            "    test_result = task_completion_time(2.0, 1.0, 0.5, 15.0, 1, 2.5)\n",
            "  File \"<string>\", line 91, in _out_task_completion_time\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/traceback_util.py\", line 195, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 264, in cache_miss\n",
            "    executable, pgle_profiler, const_args) = _python_pjit_helper(\n",
            "                                             ~~~~~~~~~~~~~~~~~~~^\n",
            "        fun, jit_info, *args, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 136, in _python_pjit_helper\n",
            "    p, args_flat = _infer_params(fun, jit_info, args, kwargs)\n",
            "                   ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 630, in _infer_params\n",
            "    return _infer_params_internal(fun, ji, args, kwargs)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 655, in _infer_params_internal\n",
            "    p, args_flat = _infer_params_impl(\n",
            "                   ~~~~~~~~~~~~~~~~~~^\n",
            "        fun, ji, ctx_mesh, dbg, args, kwargs, in_avals=avals)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 551, in _infer_params_impl\n",
            "    jaxpr, consts, out_avals = _create_pjit_jaxpr(\n",
            "                               ~~~~~~~~~~~~~~~~~~^\n",
            "        flat_fun, in_type, qdd_token, IgnoreKey(ji.inline))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/linear_util.py\", line 496, in memoized_fun\n",
            "    ans = call(fun, *args)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 1184, in _create_pjit_jaxpr\n",
            "    jaxpr, global_out_avals, consts = pe.trace_to_jaxpr_dynamic(fun, in_type)\n",
            "                                      ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/profiler.py\", line 359, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/interpreters/partial_eval.py\", line 2409, in trace_to_jaxpr_dynamic\n",
            "    ans = fun.call_wrapped(*in_tracers)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/linear_util.py\", line 212, in call_wrapped\n",
            "    return self.f_transformed(*args, **kwargs)\n",
            "           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
            "    ans = f(*py_args, **py_kwargs)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/linear_util.py\", line 421, in _get_result_paths_thunk\n",
            "    ans = _fun(*args, **kwargs)\n",
            "  File \"<string>\", line 31, in _jit_task_completion_time\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/memo/lib.py\", line 16, in maxx\n",
            "    return jnp.max(t, axis=tuple(-1 - d for d in dims), keepdims=True)\n",
            "           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/numpy/reductions.py\", line 476, in max\n",
            "    return _reduce_max(a, axis=_ensure_optional_axes(axis), out=out,\n",
            "                       keepdims=keepdims, initial=initial, where=where)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/traceback_util.py\", line 195, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 264, in cache_miss\n",
            "    executable, pgle_profiler, const_args) = _python_pjit_helper(\n",
            "                                             ~~~~~~~~~~~~~~~~~~~^\n",
            "        fun, jit_info, *args, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 136, in _python_pjit_helper\n",
            "    p, args_flat = _infer_params(fun, jit_info, args, kwargs)\n",
            "                   ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 630, in _infer_params\n",
            "    return _infer_params_internal(fun, ji, args, kwargs)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 655, in _infer_params_internal\n",
            "    p, args_flat = _infer_params_impl(\n",
            "                   ~~~~~~~~~~~~~~~~~~^\n",
            "        fun, ji, ctx_mesh, dbg, args, kwargs, in_avals=avals)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 551, in _infer_params_impl\n",
            "    jaxpr, consts, out_avals = _create_pjit_jaxpr(\n",
            "                               ~~~~~~~~~~~~~~~~~~^\n",
            "        flat_fun, in_type, qdd_token, IgnoreKey(ji.inline))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/linear_util.py\", line 496, in memoized_fun\n",
            "    ans = call(fun, *args)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 1184, in _create_pjit_jaxpr\n",
            "    jaxpr, global_out_avals, consts = pe.trace_to_jaxpr_dynamic(fun, in_type)\n",
            "                                      ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/profiler.py\", line 359, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/interpreters/partial_eval.py\", line 2409, in trace_to_jaxpr_dynamic\n",
            "    ans = fun.call_wrapped(*in_tracers)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/linear_util.py\", line 212, in call_wrapped\n",
            "    return self.f_transformed(*args, **kwargs)\n",
            "           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
            "    ans = f(*py_args, **py_kwargs)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/api_util.py\", line 318, in _argnames_partial\n",
            "    return _fun(*args, **kwargs)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/api_util.py\", line 292, in _argnums_partial\n",
            "    return _fun(*args, **kwargs)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/linear_util.py\", line 421, in _get_result_paths_thunk\n",
            "    ans = _fun(*args, **kwargs)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/numpy/reductions.py\", line 400, in _reduce_max\n",
            "    return _reduction(a, \"max\", lax.max, -np.inf, has_identity=False,\n",
            "                      axis=axis, dtype=dtype, out=out, keepdims=keepdims,\n",
            "                      initial=initial, where_=where, parallel_reduce=lax_parallel.pmax)\n",
            "  File \"/Users/mannendriolivares/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/numpy/reductions.py\", line 124, in _reduction\n",
            "    raise ValueError(f\"zero-size array to reduction operation {name} which has no identity\")\n",
            "ValueError: zero-size array to reduction operation max which has no identity\n"
          ]
        }
      ],
      "source": [
        "# POMDP generative model for task completion times\n",
        "# We model the probability of completing each task at each timestep\n",
        "\n",
        "class CompletionTime(IntEnum):\n",
        "    \"\"\"Completion timestep (0 to H-1, or H for never completed)\"\"\"\n",
        "    pass\n",
        "\n",
        "# Create enum values for timesteps 0 to H\n",
        "for t in range(H + 1):\n",
        "    setattr(CompletionTime, f'T{t}', t)\n",
        "\n",
        "COMPLETION_TIMES = np.array(list(range(H + 1)))  # 0 to H\n",
        "\n",
        "# ruff: noqa\n",
        "@no_type_check\n",
        "@memo\n",
        "def task_completion_time[t_complete: CompletionTime](\n",
        "    theta_j,  # θ[p, j] for this task\n",
        "    alpha,  # α[p]\n",
        "    beta_u,  # β_u\n",
        "    V_j,  # V[j] reward points\n",
        "    deadline_day,  # d[j] deadline day\n",
        "    mu_prior_j  # Prior mean μ[p, j] (for prior, not used in likelihood here)\n",
        "):\n",
        "    \"\"\"\n",
        "    Generative model for when task j gets completed.\n",
        "    \n",
        "    Models the completion time distribution based on POMDP dynamics:\n",
        "    - At each timestep t, compute score[j] = eta * (V[j] * γ^lateness - θ[p,j])\n",
        "    - Probability of attempting task j (softmax over incomplete tasks)\n",
        "    - Probability of completing given attempt: sigmoid(α[p] + β_u * urgency - θ[p,j])\n",
        "    - Overall: probability of completing at t is attempt_prob * completion_prob * (1 - earlier_completion)\n",
        "    \n",
        "    For computational efficiency, we approximate by computing utility at each timestep\n",
        "    and using softmax to get completion time distribution.\n",
        "    \n",
        "    Args:\n",
        "        t_complete: Completion timestep (axis) - 0 to H (H = never completed)\n",
        "        theta_j: Latent cost θ[p, j]\n",
        "        alpha: Baseline work propensity α[p]\n",
        "        beta_u: Urgency sensitivity β_u\n",
        "        V_j: Reward points\n",
        "        deadline_day: Deadline day\n",
        "        mu_prior_j: Prior mean μ[p, j]\n",
        "    \n",
        "    Returns:\n",
        "        Probability of completing at timestep t_complete\n",
        "    \"\"\"\n",
        "    # Compute utility for completing at timestep t_complete\n",
        "    # Follow the pattern from reward_only_memo_baseline: inline everything directly\n",
        "    # Memo doesn't support assignments, if statements, jnp.where, or helper function calls in expressions\n",
        "    # Use Python ternary operator and inline all computations\n",
        "    \n",
        "    # Inline day calculation: day = t_complete // 3\n",
        "    # Inline lateness: max(0, day - deadline_day) = (day - deadline_day) if (day - deadline_day) > 0 else 0\n",
        "    # Use literal values: ETA=1.0 (removed since it's 1.0), GAMMA=0.9\n",
        "    \n",
        "    # Utility calculation following reward_only_memo_baseline pattern\n",
        "    # Compute day from timestep: day = t_complete / 3 (use regular division, memo should handle it)\n",
        "    # Compute lateness: lat = (day - deadline_day) if (day - deadline_day) > 0 else 0\n",
        "    # Utility = V_j * (0.9 ** lat) - theta_j + alpha + beta_u * lat - theta_j\n",
        "    # Fully inline all calculations - no lambda, no assignments, just pure expressions\n",
        "    # day_diff = (t_complete / 3.0) - deadline_day, lat = day_diff if day_diff > 0 else 0\n",
        "    agent: chooses(t_complete in CompletionTime, wpp=exp(\n",
        "        -20.0 if t_complete == 21 else (\n",
        "            # Compute day_diff once and use it (but we can't assign, so compute it where needed)\n",
        "            # For lateness: ((t_complete / 3.0) - deadline_day) if ((t_complete / 3.0) - deadline_day) > 0 else 0\n",
        "            V_j * (0.9 ** (((t_complete / 3.0) - deadline_day) if ((t_complete / 3.0) - deadline_day) > 0 else 0)) - theta_j + \n",
        "            alpha + beta_u * (((t_complete / 3.0) - deadline_day) if ((t_complete / 3.0) - deadline_day) > 0 else 0) - theta_j\n",
        "        )\n",
        "    ))\n",
        "    \n",
        "    return Pr[agent.t_complete == t_complete]\n",
        "\n",
        "print(\"Testing task_completion_time model...\")\n",
        "try:\n",
        "    test_result = task_completion_time(2.0, 1.0, 0.5, 15.0, 1, 2.5)\n",
        "    print(f\"Output shape: {test_result.shape}\")\n",
        "    print(f\"Sum: {test_result.sum():.4f}\")\n",
        "    print(f\"First few probabilities: {test_result[:5]}\")\n",
        "    print(\"Model works!\")\n",
        "except Exception as e:\n",
        "    print(f\"Model test error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log-likelihood function created\n"
          ]
        }
      ],
      "source": [
        "def compute_log_likelihood_participant(\n",
        "    params,  # [theta_0, ..., theta_{n_tasks-1}, alpha, beta_u]\n",
        "    participant_idx,\n",
        "    observed_completion_times,  # Dict mapping task_idx -> completion_timestep (or None)\n",
        "    V_array,  # Array of V[j] for all tasks\n",
        "    deadlines_array,  # Array of d[j] for all tasks\n",
        "    mu_prior_participant  # Array of μ[p, j] for this participant\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute log-likelihood for a single participant.\n",
        "    \n",
        "    This function implements MAP inference by computing:\n",
        "    log P(θ, α, β_u | observations) ∝ log P(observations | θ, α, β_u) + log P(θ, α, β_u)\n",
        "    \n",
        "    Args:\n",
        "        params: Parameter vector [θ[0], ..., θ[n_tasks-1], α, β_u]\n",
        "        participant_idx: Participant index\n",
        "        observed_completion_times: Dict {task_idx: completion_timestep or None}\n",
        "        V_array: Reward points for all tasks\n",
        "        deadlines_array: Deadline days for all tasks\n",
        "        mu_prior_participant: Prior means for this participant\n",
        "    \n",
        "    Returns:\n",
        "        Negative log-likelihood (for minimization)\n",
        "    \"\"\"\n",
        "    n_tasks_local = len(V_array)\n",
        "    theta = params[:n_tasks_local]\n",
        "    alpha = params[n_tasks_local]\n",
        "    beta_u = params[n_tasks_local + 1]\n",
        "    \n",
        "    # Prior terms (log probabilities)\n",
        "    # θ[p, j] ~ Normal(μ[p, j], σ_θ)\n",
        "    log_prior_theta = jnp.sum(jax.scipy.stats.norm.logpdf(theta, mu_prior_participant, SIGMA_THETA))\n",
        "    # α[p] ~ Normal(0, σ_α)\n",
        "    log_prior_alpha = jax.scipy.stats.norm.logpdf(alpha, 0.0, SIGMA_ALPHA)\n",
        "    # β_u ~ Normal(0, σ_β)\n",
        "    log_prior_beta = jax.scipy.stats.norm.logpdf(beta_u, 0.0, SIGMA_BETA)\n",
        "    log_prior = log_prior_theta + log_prior_alpha + log_prior_beta\n",
        "    \n",
        "    # Likelihood term: product over tasks\n",
        "    # P(observations | θ, α, β_u) = ∏_j P(t_complete[j] | θ[p,j], α[p], β_u)\n",
        "    log_likelihood = 0.0\n",
        "    \n",
        "    for task_idx in range(n_tasks_local):\n",
        "        # Get model probabilities from memo model\n",
        "        # Convert numpy arrays to JAX arrays explicitly (jnp.asarray works in traced context)\n",
        "        # Ensure all inputs are JAX-compatible\n",
        "        probs = task_completion_time(\n",
        "            theta[task_idx],  # Already JAX\n",
        "            alpha,  # Already JAX\n",
        "            beta_u,  # Already JAX\n",
        "            jnp.asarray(V_array[task_idx], dtype=jnp.float64),  # Convert numpy to JAX\n",
        "            jnp.asarray(deadlines_array[task_idx], dtype=jnp.int32),  # Convert numpy to JAX\n",
        "            jnp.asarray(mu_prior_participant[task_idx], dtype=jnp.float64)  # Convert numpy to JAX\n",
        "        )\n",
        "        \n",
        "        # Get observed completion time\n",
        "        obs_time = observed_completion_times.get(task_idx, None)\n",
        "        \n",
        "        if obs_time is not None:\n",
        "            # Task was completed at timestep obs_time\n",
        "            # Clamp to valid range [0, 21] and use Python int for indexing\n",
        "            obs_time_clamped = int(np.clip(obs_time, 0, 21))\n",
        "            # Use Python int for array indexing (JAX arrays support this)\n",
        "            prob = probs[obs_time_clamped]\n",
        "            log_likelihood += jnp.log(prob + 1e-10)\n",
        "        else:\n",
        "            # Task was never completed (completion at timestep 21)\n",
        "            # probs should have length 22 (0-21), so index 21 is the last element\n",
        "            prob = probs[21]  # Never completed probability\n",
        "            log_likelihood += jnp.log(prob + 1e-10)\n",
        "    \n",
        "    # Return negative log-likelihood (for minimization)\n",
        "    return -(log_prior + log_likelihood)\n",
        "\n",
        "# Create JAX-compatible version with gradients\n",
        "compute_loss_and_grad = jax.value_and_grad(compute_log_likelihood_participant)\n",
        "\n",
        "print(\"Log-likelihood function created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task rewards V: [20.  5. 25. 10. 20. 15.  5. 15.]\n",
            "Task deadlines d: [3 3 5 3 1 5 1 1]\n",
            "\n",
            "Fitting parameters for aphid-1...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "zero-size array to reduction operation max which has no identity",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[136]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(loss), np.array([\u001b[38;5;28mfloat\u001b[39m(g) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grad])\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Optimize\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m result = \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmaxiter\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Extract fitted parameters\u001b[39;00m\n\u001b[32m     51\u001b[39m n_tasks_local = \u001b[38;5;28mlen\u001b[39m(tasks)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/scipy/optimize/_minimize.py:784\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    781\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    782\u001b[39m                              **options)\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    787\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    788\u001b[39m                         **options)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/scipy/optimize/_lbfgsb_py.py:413\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[39m\n\u001b[32m    410\u001b[39m     x0 = np.clip(x0, bounds[\u001b[32m0\u001b[39m], bounds[\u001b[32m1\u001b[39m])\n\u001b[32m    412\u001b[39m \u001b[38;5;66;03m# _prepare_scalar_function can use bounds=None to represent no bounds\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m sf = \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    418\u001b[39m func_and_grad = sf.fun_and_grad\n\u001b[32m    420\u001b[39m nbd = zeros(n, np.int32)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/scipy/optimize/_optimize.py:310\u001b[39m, in \u001b[36m_prepare_scalar_function\u001b[39m\u001b[34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess, workers)\u001b[39m\n\u001b[32m    306\u001b[39m workers = workers \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mmap\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m sf = \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:274\u001b[39m, in \u001b[36mScalarFunction.__init__\u001b[39m\u001b[34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon, workers)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;66;03m# Initial function evaluation\u001b[39;00m\n\u001b[32m    273\u001b[39m \u001b[38;5;28mself\u001b[39m._nfev = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# Initial gradient evaluation\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[38;5;28mself\u001b[39m._wrapped_grad = _ScalarGradWrapper(\n\u001b[32m    278\u001b[39m     grad,\n\u001b[32m    279\u001b[39m     fun=\u001b[38;5;28mself\u001b[39m._wrapped_fun,\n\u001b[32m    280\u001b[39m     args=args,\n\u001b[32m    281\u001b[39m     finite_diff_options=finite_diff_options,\n\u001b[32m    282\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:353\u001b[39m, in \u001b[36mScalarFunction._update_fun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    352\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f_updated:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m         fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m         \u001b[38;5;28mself\u001b[39m._nfev += \u001b[32m1\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fx < \u001b[38;5;28mself\u001b[39m._lowest_f:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/scipy/_lib/_util.py:590\u001b[39m, in \u001b[36m_ScalarFunctionWrapper.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    588\u001b[39m     \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m    589\u001b[39m     \u001b[38;5;66;03m# The user of this class might want `x` to remain unchanged.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m     fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m     \u001b[38;5;28mself\u001b[39m.nfev += \u001b[32m1\u001b[39m\n\u001b[32m    593\u001b[39m     \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/scipy/optimize/_optimize.py:80\u001b[39m, in \u001b[36mMemoizeJac.__call__\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args):\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/scipy/optimize/_optimize.py:74\u001b[39m, in \u001b[36mMemoizeJac._compute_if_needed\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(x == \u001b[38;5;28mself\u001b[39m.x) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.x = np.asarray(x).copy()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     fg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.jac = fg[\u001b[32m1\u001b[39m]\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = fg[\u001b[32m0\u001b[39m]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[136]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(x):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     loss, grad = \u001b[43mcompute_loss_and_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mp_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobs_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mV_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadlines_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmu_prior\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(loss), np.array([\u001b[38;5;28mfloat\u001b[39m(g) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grad])\n",
            "    \u001b[31m[... skipping hidden 10 frame]\u001b[39m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[135]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mcompute_log_likelihood_participant\u001b[39m\u001b[34m(params, participant_idx, observed_completion_times, V_array, deadlines_array, mu_prior_participant)\u001b[39m\n\u001b[32m     42\u001b[39m log_likelihood = \u001b[32m0.0\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_tasks_local):\n\u001b[32m     45\u001b[39m     \u001b[38;5;66;03m# Get model probabilities from memo model\u001b[39;00m\n\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# Convert numpy arrays to JAX arrays explicitly (jnp.asarray works in traced context)\u001b[39;00m\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# Ensure all inputs are JAX-compatible\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     probs = \u001b[43mtask_completion_time\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Already JAX\u001b[39;49;00m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Already JAX\u001b[39;49;00m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Already JAX\u001b[39;49;00m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Convert numpy to JAX\u001b[39;49;00m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeadlines_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Convert numpy to JAX\u001b[39;49;00m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmu_prior_participant\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Convert numpy to JAX\u001b[39;49;00m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# Get observed completion time\u001b[39;00m\n\u001b[32m     58\u001b[39m     obs_time = observed_completion_times.get(task_idx, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<string>:91\u001b[39m, in \u001b[36m_out_task_completion_time\u001b[39m\u001b[34m(theta_j, alpha, beta_u, V_j, deadline_day, mu_prior_j, return_aux, return_pandas, return_xarray, return_cost, print_table)\u001b[39m\n",
            "    \u001b[31m[... skipping hidden 13 frame]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<string>:31\u001b[39m, in \u001b[36m_jit_task_completion_time\u001b[39m\u001b[34m(theta_j, alpha, beta_u, V_j, deadline_day, mu_prior_j, lit_3, lit_5, op_neg_6, lit_7, lit_8, lit_10, lit_12, lit_14, lit_16, lit_18, lit_20, lit_23, lit_25, lit_27, lit_29, lit_31, lit_33, lit_35, lit_37, lit_39, lit_42)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/memo/lib.py:16\u001b[39m, in \u001b[36mmaxx\u001b[39m\u001b[34m(t, dims)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dims == ():\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/numpy/reductions.py:476\u001b[39m, in \u001b[36mmax\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;129m@export\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmax\u001b[39m(a: ArrayLike, axis: Axis = \u001b[38;5;28;01mNone\u001b[39;00m, out: \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    407\u001b[39m         keepdims: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m, initial: ArrayLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    408\u001b[39m         where: ArrayLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> Array:\n\u001b[32m    409\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Return the maximum of the array elements along a given axis.\u001b[39;00m\n\u001b[32m    410\u001b[39m \n\u001b[32m    411\u001b[39m \u001b[33;03m  JAX implementation of :func:`numpy.max`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    474\u001b[39m \u001b[33;03m    Array([[0, 0, 0, 0]], dtype=int32)\u001b[39;00m\n\u001b[32m    475\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reduce_max\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_ensure_optional_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
            "    \u001b[31m[... skipping hidden 15 frame]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/numpy/reductions.py:400\u001b[39m, in \u001b[36m_reduce_max\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;129m@api\u001b[39m.jit(static_argnames=(\u001b[33m'\u001b[39m\u001b[33maxis\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mkeepdims\u001b[39m\u001b[33m'\u001b[39m), inline=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_reduce_max\u001b[39m(a: ArrayLike, axis: Axis = \u001b[38;5;28;01mNone\u001b[39;00m, dtype: DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    398\u001b[39m                 out: \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, keepdims: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    399\u001b[39m                 initial: ArrayLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, where: ArrayLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> Array:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_identity\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                    \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_reduce\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlax_parallel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpmax\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ccs-final-project/venv/lib/python3.13/site-packages/jax/_src/numpy/reductions.py:124\u001b[39m, in \u001b[36m_reduction\u001b[39m\u001b[34m(a, name, op, init_val, has_identity, preproc, bool_op, upcast_f16_for_computation, axis, dtype, out, keepdims, initial, where_, parallel_reduce, promote_integers)\u001b[39m\n\u001b[32m    122\u001b[39m   shape = np.shape(a)\n\u001b[32m    123\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _all(shape[d] >= \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m pos_dims):\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mzero-size array to reduction operation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m which has no identity\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    126\u001b[39m result_dtype: DType\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mValueError\u001b[39m: zero-size array to reduction operation max which has no identity"
          ]
        }
      ],
      "source": [
        "# Prepare data arrays for fitting\n",
        "V_array = np.array([task_data[t]['points'] for t in tasks])\n",
        "deadlines_array = np.array([task_data[t]['deadline_day'] for t in tasks])\n",
        "\n",
        "print(\"Task rewards V:\", V_array)\n",
        "print(\"Task deadlines d:\", deadlines_array)\n",
        "\n",
        "# Fit parameters for each participant\n",
        "fitted_params = {}\n",
        "\n",
        "for p_idx, participant in enumerate(participants):\n",
        "    print(f\"\\nFitting parameters for {participant}...\")\n",
        "    \n",
        "    # Prepare observed completion times for this participant\n",
        "    obs_times = {}\n",
        "    for t_idx, task in enumerate(tasks):\n",
        "        comp_time = completion_times[participant].get(task, None)\n",
        "        if comp_time is not None:\n",
        "            obs_times[t_idx] = comp_time\n",
        "        # else: task not completed, will be handled as completion at H\n",
        "    \n",
        "    # Initialize parameters\n",
        "    # Start with prior means for theta, small values for alpha and beta_u\n",
        "    initial_theta = mu_prior[p_idx, :].copy()\n",
        "    initial_alpha = 0.0\n",
        "    initial_beta_u = 0.0\n",
        "    initial_params = np.concatenate([initial_theta, [initial_alpha, initial_beta_u]])\n",
        "    \n",
        "    # Objective function for scipy.optimize\n",
        "    def objective(x):\n",
        "        loss, grad = compute_loss_and_grad(\n",
        "            x,\n",
        "            p_idx,\n",
        "            obs_times,\n",
        "            V_array,\n",
        "            deadlines_array,\n",
        "            mu_prior[p_idx, :]\n",
        "        )\n",
        "        return float(loss), np.array([float(g) for g in grad])\n",
        "    \n",
        "    # Optimize\n",
        "    result = minimize(\n",
        "        objective,\n",
        "        x0=initial_params,\n",
        "        method='L-BFGS-B',\n",
        "        jac=True,\n",
        "        options={'maxiter': 100}\n",
        "    )\n",
        "    \n",
        "    # Extract fitted parameters\n",
        "    n_tasks_local = len(tasks)\n",
        "    fitted_theta = result.x[:n_tasks_local]\n",
        "    fitted_alpha = result.x[n_tasks_local]\n",
        "    fitted_beta_u = result.x[n_tasks_local + 1]\n",
        "    \n",
        "    fitted_params[participant] = {\n",
        "        'theta': fitted_theta,\n",
        "        'alpha': fitted_alpha,\n",
        "        'beta_u': fitted_beta_u\n",
        "    }\n",
        "    \n",
        "    print(f\"  α = {fitted_alpha:.3f}, β_u = {fitted_beta_u:.3f}\")\n",
        "    print(f\"  θ = {fitted_theta}\")\n",
        "\n",
        "# Extract shared beta_u (use mean across participants)\n",
        "shared_beta_u = np.mean([fitted_params[p]['beta_u'] for p in participants])\n",
        "print(f\"\\nShared β_u (mean): {shared_beta_u:.3f}\")\n",
        "\n",
        "# Update all participants to use shared beta_u\n",
        "for participant in participants:\n",
        "    fitted_params[participant]['beta_u'] = shared_beta_u\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization 1: Predicted vs Observed Completion Days\n",
        "\n",
        "For each participant, plot predicted completion-day distribution per task vs observed completion day.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute predicted completion day distributions for each participant-task\n",
        "predictions = []\n",
        "\n",
        "for p_idx, participant in enumerate(participants):\n",
        "    params = fitted_params[participant]\n",
        "    theta = params['theta']\n",
        "    alpha = params['alpha']\n",
        "    beta_u = params['beta_u']\n",
        "    \n",
        "    for t_idx, task in enumerate(tasks):\n",
        "        # Get model probabilities\n",
        "        probs = task_completion_time(\n",
        "            float(theta[t_idx]),\n",
        "            float(alpha),\n",
        "            float(beta_u),\n",
        "            float(V_array[t_idx]),\n",
        "            int(deadlines_array[t_idx]),\n",
        "            float(mu_prior[p_idx, t_idx])\n",
        "        )\n",
        "        \n",
        "        # Convert timestep probabilities to day probabilities\n",
        "        day_probs = np.zeros(8)  # Days 0-7\n",
        "        for timestep in range(min(H, len(probs))):\n",
        "            day = day_from_timestep(timestep)\n",
        "            if day < 8:\n",
        "                day_probs[day] += probs[timestep]\n",
        "        # Never completed goes to day 7+ (or we can ignore it)\n",
        "        \n",
        "        # Compute expected completion day\n",
        "        expected_day = np.sum([d * day_probs[d] for d in range(8)])\n",
        "        \n",
        "        # Get observed completion day\n",
        "        obs_time = completion_times[participant].get(task, None)\n",
        "        if obs_time is not None:\n",
        "            obs_day = day_from_timestep(obs_time)\n",
        "        else:\n",
        "            obs_day = None\n",
        "        \n",
        "        predictions.append({\n",
        "            'participant': participant,\n",
        "            'task': task,\n",
        "            'expected_day': expected_day,\n",
        "            'observed_day': obs_day,\n",
        "            'day_probs': day_probs\n",
        "        })\n",
        "\n",
        "df_predictions = pd.DataFrame(predictions)\n",
        "\n",
        "# Plot: Predicted vs Observed for each participant\n",
        "n_participants_plot = len(participants)\n",
        "n_cols = 2\n",
        "n_rows = (n_participants_plot + n_cols - 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 5 * n_rows))\n",
        "if n_participants_plot == 1:\n",
        "    axes = [axes]\n",
        "else:\n",
        "    axes = axes.flatten()\n",
        "\n",
        "for p_idx, participant in enumerate(participants):\n",
        "    ax = axes[p_idx]\n",
        "    participant_data = df_predictions[df_predictions['participant'] == participant]\n",
        "    \n",
        "    # Plot predicted (expected) completion days\n",
        "    ax.scatter(\n",
        "        range(len(participant_data)),\n",
        "        participant_data['expected_day'],\n",
        "        label='Predicted (expected)',\n",
        "        s=100,\n",
        "        alpha=0.7,\n",
        "        color='red',\n",
        "        marker='s'\n",
        "    )\n",
        "    \n",
        "    # Plot observed completion days\n",
        "    observed_data = participant_data[participant_data['observed_day'].notna()]\n",
        "    ax.scatter(\n",
        "        [i for i, (_, row) in enumerate(participant_data.iterrows()) if pd.notna(row['observed_day'])],\n",
        "        observed_data['observed_day'],\n",
        "        label='Observed',\n",
        "        s=100,\n",
        "        alpha=0.7,\n",
        "        color='blue',\n",
        "        marker='o'\n",
        "    )\n",
        "    \n",
        "    # Add task labels\n",
        "    ax.set_xticks(range(len(participant_data)))\n",
        "    ax.set_xticklabels([t[:20] + '...' if len(t) > 20 else t for t in participant_data['task']], \n",
        "                       rotation=45, ha='right', fontsize=9)\n",
        "    \n",
        "    ax.set_ylabel('Completion Day', fontsize=11)\n",
        "    ax.set_title(f'{participant}', fontsize=12, fontweight='bold')\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_ylim(-0.5, 7.5)\n",
        "\n",
        "# Hide unused subplots\n",
        "for i in range(n_participants_plot, len(axes)):\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Predicted vs Observed Completion Days (by Participant)', \n",
        "             fontsize=14, fontweight='bold', y=1.0)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "\n",
        "plot_path = PLOTS_DIR / 'procrastination_pomdp_predicted_vs_observed.png'\n",
        "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "print(f\"Figure saved as {plot_path}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for scatter plots\n",
        "scatter_data = []\n",
        "\n",
        "for p_idx, participant in enumerate(participants):\n",
        "    params = fitted_params[participant]\n",
        "    theta = params['theta']\n",
        "    \n",
        "    for t_idx, task in enumerate(tasks):\n",
        "        rating = ratings[participant][task]\n",
        "        \n",
        "        # Extract ratings\n",
        "        diff = rating['perceived_difficulty'] if rating['perceived_difficulty'] is not None else np.nan\n",
        "        conc = rating['perceived_concreteness'] if rating['perceived_concreteness'] is not None else np.nan\n",
        "        dur = rating['perceived_duration'] if rating['perceived_duration'] is not None else np.nan\n",
        "        reward = rating['perceived_reward'] if rating['perceived_reward'] is not None else np.nan\n",
        "        \n",
        "        scatter_data.append({\n",
        "            'participant': participant,\n",
        "            'task': task,\n",
        "            'theta': theta[t_idx],\n",
        "            'difficulty': diff,\n",
        "            'concreteness_inv': 10 - conc if not np.isnan(conc) else np.nan,\n",
        "            'duration': dur,\n",
        "            'rewardless': 10 - reward if not np.isnan(reward) else np.nan\n",
        "        })\n",
        "\n",
        "df_scatter = pd.DataFrame(scatter_data)\n",
        "\n",
        "# Create subplots for each rating dimension\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "rating_dims = [\n",
        "    ('difficulty', 'Perceived Difficulty'),\n",
        "    ('concreteness_inv', '10 - Perceived Concreteness'),\n",
        "    ('duration', 'Perceived Duration'),\n",
        "    ('rewardless', '10 - Perceived Reward')\n",
        "]\n",
        "\n",
        "for idx, (dim, label) in enumerate(rating_dims):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # Filter out NaN values\n",
        "    plot_data = df_scatter[[dim, 'theta']].dropna()\n",
        "    \n",
        "    if len(plot_data) > 0:\n",
        "        # Scatter plot\n",
        "        ax.scatter(plot_data[dim], plot_data['theta'], alpha=0.6, s=80, color='steelblue')\n",
        "        \n",
        "        # Regression line\n",
        "        from scipy.stats import linregress\n",
        "        slope, intercept, r_value, p_value, std_err = linregress(plot_data[dim], plot_data['theta'])\n",
        "        x_line = np.linspace(plot_data[dim].min(), plot_data[dim].max(), 100)\n",
        "        y_line = slope * x_line + intercept\n",
        "        ax.plot(x_line, y_line, 'r--', alpha=0.8, linewidth=2, \n",
        "               label=f'r={r_value:.3f}, p={p_value:.3f}')\n",
        "        \n",
        "        ax.set_xlabel(label, fontsize=11)\n",
        "        ax.set_ylabel('Fitted θ[p, j]', fontsize=11)\n",
        "        ax.set_title(f'θ vs {label}', fontsize=12, fontweight='bold')\n",
        "        ax.legend(fontsize=10)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, 'No data', ha='center', va='center', transform=ax.transAxes)\n",
        "        ax.set_title(f'θ vs {label}', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Fitted θ[p, j] vs Rating Dimensions', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "\n",
        "plot_path = PLOTS_DIR / 'procrastination_pomdp_theta_vs_ratings.png'\n",
        "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "print(f\"Figure saved as {plot_path}\")\n",
        "plt.show()\n",
        "\n",
        "# Print correlations\n",
        "print(\"\\nCorrelations between θ and rating dimensions:\")\n",
        "for dim, label in rating_dims:\n",
        "    plot_data = df_scatter[[dim, 'theta']].dropna()\n",
        "    if len(plot_data) > 1:\n",
        "        corr = plot_data[dim].corr(plot_data['theta'])\n",
        "        print(f\"  {label}: r = {corr:.3f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
